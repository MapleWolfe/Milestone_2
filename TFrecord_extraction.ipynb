{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1ud4nysR8AygsWvB0kf3c1Jaz4RlN_q08",
      "authorship_tag": "ABX9TyM57W+YyiS+YG0AMnngw/7Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MapleWolfe/Milestone_2/blob/Jai/TFrecord_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data extraction from TF records"
      ],
      "metadata": {
        "id": "IuuckSotcRHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installs, imports, pre-sets"
      ],
      "metadata": {
        "id": "Uv1syv3gdvb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_fG6RA56XD_4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage\n",
        "from scipy.ndimage import distance_transform_edt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading TF records from google drive"
      ],
      "metadata": {
        "id": "B_yF4lBdd2_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's mount the drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# let's look into the zip file stored in the google drive\n",
        "wild_fire_file_path = '/content/drive/MyDrive/next_day_wildfire.zip'\n",
        "wildfire_zip =  zipfile.ZipFile(wild_fire_file_path, 'r')\n",
        "file_names = wildfire_zip.namelist()\n",
        "\n",
        "print('number of TF records:', len(file_names))\n",
        "print('file names of tf records within the zip:')\n",
        "print(file_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrCeIqHYul-S",
        "outputId": "216e749d-063a-4fe8-e043-dac76829a2ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "number of TF records: 19\n",
            "file names of tf records within the zip:\n",
            "['next_day_wildfire_spread_eval_00.tfrecord', 'next_day_wildfire_spread_eval_01.tfrecord', 'next_day_wildfire_spread_test_00.tfrecord', 'next_day_wildfire_spread_test_01.tfrecord', 'next_day_wildfire_spread_train_00.tfrecord', 'next_day_wildfire_spread_train_01.tfrecord', 'next_day_wildfire_spread_train_02.tfrecord', 'next_day_wildfire_spread_train_03.tfrecord', 'next_day_wildfire_spread_train_04.tfrecord', 'next_day_wildfire_spread_train_05.tfrecord', 'next_day_wildfire_spread_train_06.tfrecord', 'next_day_wildfire_spread_train_07.tfrecord', 'next_day_wildfire_spread_train_08.tfrecord', 'next_day_wildfire_spread_train_09.tfrecord', 'next_day_wildfire_spread_train_10.tfrecord', 'next_day_wildfire_spread_train_11.tfrecord', 'next_day_wildfire_spread_train_12.tfrecord', 'next_day_wildfire_spread_train_13.tfrecord', 'next_day_wildfire_spread_train_14.tfrecord']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipping one file at a time\n",
        "def one_file_unzip(tf_record_file_name, zipfile_variable):\n",
        "  extracted_record_path = zipfile_variable.extract(tf_record_file_name)\n",
        "  raw_dataset = tf.data.TFRecordDataset(extracted_record_path)\n",
        "  return raw_dataset\n",
        "\n",
        "# yielding out one record at a time\n",
        "def extract_one_row(tf_record_dataset):\n",
        "  for i, raw_record in enumerate(tf_record_dataset.take(raw_dataset.cardinality().numpy())):\n",
        "    one_record_dict = {}\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "    for key, feature in example.features.feature.items():\n",
        "\n",
        "      kind = feature.WhichOneof('kind')\n",
        "      one_record_dict[key] = np.array(getattr(feature, kind).value).reshape(64,64)\n",
        "#remove this 'break' below\n",
        "    break\n",
        "  yield one_record_dict"
      ],
      "metadata": {
        "id": "QuxrZXk6cQEZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## let's create features from all images"
      ],
      "metadata": {
        "id": "XErZ3dz7Hs19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### feature description given by dataset maker"
      ],
      "metadata": {
        "id": "hD7ndnzBQ2A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data variables\n",
        "\n",
        "INPUT_FEATURES = ['elevation', 'th', 'vs',  'tmmn', 'tmmx', 'sph',\n",
        "                  'pr', 'pdsi', 'NDVI', 'population', 'erc', 'PrevFireMask']\n",
        "\n",
        "OUTPUT_FEATURES = ['FireMask']\n",
        "\n",
        "\n",
        "# underlying feature value ranges:\n",
        "# (min_clip, max_clip, mean, standard deviation)\n",
        "\n",
        "feature_description_dict = {\n",
        "    # Elevation in m: between 0.1 percentile and 99.9 percentile\n",
        "    'elevation': (0.0, 3141.0, 657.3003, 649.0147),\n",
        "\n",
        "    # Palmer Drought Severity Index: between 0.1 percentile and 99.9 percentile\n",
        "    'pdsi': (-6.12974870967865, 7.876040384292651, -0.0052714925, 2.6823447),\n",
        "\n",
        "    #Vegetation index times 10,000: between -1 and 1\n",
        "    'NDVI': (-9821.0, 9996.0, 5157.625, 2466.6677),\n",
        "\n",
        "    # Precipitation in mm: between 0.0 and 99.9 percentile\n",
        "    'pr': (0.0, 44.53038024902344, 1.7398051, 4.482833),\n",
        "\n",
        "    # Specific humidity: between 0 and 1\n",
        "    'sph': (0., 1., 0.0071658953, 0.0042835088),\n",
        "\n",
        "    # Wind direction in degrees clockwise from north: between 0 and 360.\n",
        "    'th': (0., 360.0, 190.32976, 72.59854),\n",
        "\n",
        "    #Min temp: between 253.15 kelvin and 99.9 percentile\n",
        "    'tmmn': (253.15, 298.94891357421875, 281.08768, 8.982386),\n",
        "\n",
        "    #Max temp: between 253.15 kelvin and 99.9 percentile\n",
        "    'tmmx': (253.15, 315.09228515625, 295.17383, 9.815496),\n",
        "\n",
        "    # Wind speed in m/s: between 0. and 99.9 percentile\n",
        "    'vs': (0.0, 10.024310074806237, 3.8500874, 1.4109988),\n",
        "\n",
        "    # NFDRS fire danger index energy release component BTU's per square foot.\n",
        "    # 0., 99.9 percentile\n",
        "    'erc': (0.0, 106.24891662597656, 37.326267, 20.846027),\n",
        "\n",
        "    # Population density: between 0 and 99.9 percentile\n",
        "    'population': (0., 2534.06298828125, 25.531384, 154.72331),\n",
        "\n",
        "    # We don't want to normalize the FireMasks.\n",
        "    # 1 indicates fire, 0 no fire, -1 unlabeled data\n",
        "    'PrevFireMask': (-1., 1., 0., 1.),\n",
        "    'FireMask': (-1., 1., 0., 1.)\n",
        "}\n"
      ],
      "metadata": {
        "id": "E4-Gd5OVc94v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Min Max scaling"
      ],
      "metadata": {
        "id": "eIZ_dwWPQlRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets define the min max scaling function\n",
        "def min_max_scaling(array,min_val,max_val):\n",
        "    scaled_array = np.clip((array - min_val) / (max_val - min_val), 0, 1)\n",
        "    return scaled_array\n",
        "\n",
        "# let's apply guassian smoothing\n",
        "def gaussian_smoothing(image_array,sigma_val):\n",
        "  smooth_array = skimage.filters.gaussian(image_array, sigma=1)\n",
        "  return smooth_array\n",
        "\n",
        "#lets get the rate of change and mean,\n",
        "def local_pixel_features(image_array,radius_val):\n",
        "  footprint = skimage.morphology.disk(radius_val)\n",
        "  gradient_array = skimage.filters.rank.gradient(image_array, footprint)\n",
        "  mean_array = skimage.filters.rank.mean(image_array, footprint)\n",
        "  return gradient_array,mean_array\n",
        "\n",
        "#use altitude edge to identify whether pixel is at a similar altitude as any pixel that has fire\n",
        "def fire_pixel_shared_altitude(row_dict, normalized_array, previous_day_fire = 'PrevFireMask'):\n",
        "  edges_array = skimage.filters.canny(normalized_array)\n",
        "  inverted_edges_array = np.logical_not(edges_array).astype(int)\n",
        "  edge_label_array = skimage.measure.label(inverted_edges_array)\n",
        "\n",
        "  previous_fire = row_dict[previous_day_fire]\n",
        "  fire_edge_labels = (edge_label_array*previous_fire)\n",
        "\n",
        "  unique_regions_with_fire = np.unique(fire_edge_labels.flatten())\n",
        "  non_zero_unique_regions = unique_regions_with_fire[unique_regions_with_fire != 0]\n",
        "\n",
        "  fire_at_same_altitude = np.isin(edge_label_array, non_zero_unique_regions).astype(int)\n",
        "  return fire_at_same_altitude\n",
        "\n",
        "def distance_to_fire(record_dict,feature):\n",
        "  fire_mask_array = record_dict[feature]\n",
        "\n",
        "# let's apply it on all features except firemasks\n",
        "def build_features(record_dict,min_max_dict,sigma_val,radius_val):\n",
        "  feature_list = record_dict.keys()\n",
        "  gradient_dict = {}\n",
        "  for a_feature in feature_list:\n",
        "    if a_feature not in ['PrevFireMask','FireMask']:\n",
        "     #min max scaling\n",
        "     feature_min = min_max_dict[a_feature][0]\n",
        "     feature_max = min_max_dict[a_feature][1]\n",
        "     scaled_array = min_max_scaling(record_dict[a_feature],feature_min,feature_max)\n",
        "     #guassian smoothing\n",
        "     smoothen_array = gaussian_smoothing(scaled_array,sigma_val)\n",
        "\n",
        "     #local pixel values: gradient values(rate of change), local mean val.\n",
        "     gradient_array,mean_array = local_pixel_features(smoothen_array,radius_val)\n",
        "\n",
        "     #lets label pixels if they are at the same elevation (to account for cliffs/mountains/chasms) as the fire\n",
        "     # here we aren't using smoothened array\n",
        "     if a_feature == 'elevation':\n",
        "      fire_at_altitude_array = fire_pixel_shared_altitude(record_dict, scaled_array)\n",
        "\n",
        "    if a_feature == 'PrevFireMask':\n",
        "\n",
        "\n",
        "\n",
        "  return gradient_dict"
      ],
      "metadata": {
        "id": "ZJKMGL66HcCG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = one_file_unzip('next_day_wildfire_spread_eval_00.tfrecord', wildfire_zip)\n",
        "output = extract_one_row(raw_dataset)\n",
        "for a_output in output:\n",
        "  print(build_features(a_output,feature_description_dict,1,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6trc2M_ooIs",
        "outputId": "ed7e15f9-0db3-4e7a-8c36-0d5d888d363a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n",
            "{'vs': array([[0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1]], dtype=uint8), 'NDVI': array([[ 9,  9,  9, ..., 15, 17, 16],\n",
            "       [11, 10,  9, ..., 18, 18, 12],\n",
            "       [16, 11, 11, ..., 19, 18, 14],\n",
            "       ...,\n",
            "       [ 9, 10, 11, ..., 29, 26, 20],\n",
            "       [ 9,  9, 10, ..., 20, 20, 20],\n",
            "       [ 9, 10, 11, ..., 20, 16, 15]], dtype=uint8), 'tmmn': array([[1, 1, 1, ..., 1, 0, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 0, 0, 1],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'PrevFireMask': array([[1, 1, 1, ..., 1, 0, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 0, 0, 1],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'pdsi': array([[1, 1, 1, ..., 2, 2, 1],\n",
            "       [2, 2, 2, ..., 2, 1, 1],\n",
            "       [2, 2, 3, ..., 3, 2, 2],\n",
            "       ...,\n",
            "       [2, 2, 2, ..., 2, 2, 2],\n",
            "       [1, 1, 2, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 1, 1, 1]], dtype=uint8), 'tmmx': array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [0, 0, 1, ..., 1, 1, 1]], dtype=uint8), 'pr': array([[0, 0, 0, ..., 2, 1, 1],\n",
            "       [1, 1, 0, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 3, 3, 2],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 1, 1, 2]], dtype=uint8), 'FireMask': array([[0, 0, 0, ..., 2, 1, 1],\n",
            "       [1, 1, 0, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 3, 3, 2],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 2, 2, 2],\n",
            "       [1, 1, 1, ..., 1, 1, 2]], dtype=uint8), 'sph': array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'population': array([[ 0,  0,  1, ...,  1,  1,  1],\n",
            "       [ 0,  0,  1, ...,  1,  1,  1],\n",
            "       [ 0,  0,  1, ...,  1,  1,  1],\n",
            "       ...,\n",
            "       [ 6, 13, 17, ...,  3,  3,  3],\n",
            "       [ 5,  8, 17, ...,  3,  3,  2],\n",
            "       [ 5,  6, 13, ...,  3,  2,  2]], dtype=uint8), 'erc': array([[0, 0, 0, ..., 2, 2, 1],\n",
            "       [0, 0, 0, ..., 3, 2, 2],\n",
            "       [1, 1, 1, ..., 3, 2, 2],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 1, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'th': array([[2, 2, 2, ..., 1, 1, 2],\n",
            "       [3, 3, 3, ..., 2, 2, 2],\n",
            "       [4, 4, 4, ..., 2, 2, 2],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 0, ..., 1, 1, 1]], dtype=uint8), 'elevation': array([[0, 0, 0, ..., 1, 1, 1],\n",
            "       [0, 0, 1, ..., 1, 1, 1],\n",
            "       [0, 1, 1, ..., 1, 1, 1],\n",
            "       ...,\n",
            "       [2, 2, 2, ..., 1, 1, 1],\n",
            "       [2, 2, 2, ..., 1, 1, 1],\n",
            "       [2, 2, 2, ..., 1, 1, 1]], dtype=uint8)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-299521f039a0>:14: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
            "  gradient_array = skimage.filters.rank.gradient(image_array, footprint)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Duabn-Fvr0T",
        "outputId": "1e4ab54d-b3bf-4b8c-d3db-3cf336af43fd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}