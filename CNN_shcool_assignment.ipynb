{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeRiBlSWP7Bm5EKNFQqkF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MapleWolfe/Milestone_2/blob/ning/CNN_shcool_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRzObht-n3Ie"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "torch.set_num_threads(4)\n",
        "torch.set_num_interop_threads(4)"
      ],
      "metadata": {
        "id": "qK4cfC4qpTT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainTransform = transforms.Compose([#add yours here!\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                    ])\n",
        "testTransform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                    ])"
      ],
      "metadata": {
        "id": "IZlGxQgXpTV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
        "        super().__init__()\n",
        "        self.outChannels = outChannels\n",
        "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(3, 24, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(24, outChannels, 5)\n",
        "        self.dense1 = nn.Linear(outChannels * 5 * 5, hiddenSize)\n",
        "        self.dropout = nn.Dropout(dropoutRate)\n",
        "        self.dense2 = nn.Linear(hiddenSize, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.activate(self.conv1(x)))\n",
        "        x = self.pool(self.activate(self.conv2(x)))\n",
        "        x = x.view(-1, self.outChannels * 5 * 5)\n",
        "        x = self.dropout(self.activate(self.dense1(x)))\n",
        "        return self.dense2(x)"
      ],
      "metadata": {
        "id": "TkrSKYpkpe4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of neurons in the first fully-connected layer\n",
        "hiddenSize = 100\n",
        "# Number of feature filters in second convolutional layer\n",
        "numFilters = 25\n",
        "# Dropout rate\n",
        "dropoutRate = 0\n",
        "# Activation function\n",
        "activation = \"ReLU\"\n",
        "# Learning rate\n",
        "learningRate = 0.001\n",
        "# Momentum for SGD optimizer\n",
        "momentum = 0.9\n",
        "# Number of training epochs\n",
        "numEpochs = 10"
      ],
      "metadata": {
        "id": "dHBTqTMNpTYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = 'assets_week2'\n",
        "trainDataset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=trainTransform)\n",
        "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "testDataset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True, transform=testTransform)\n",
        "testLoader = torch.utils.data.DataLoader(testDataset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "LTIhw_our21Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn = CNNModel(hiddenSize, numFilters, dropoutRate, activation)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(list(ann.parameters()) + list(cnn.parameters()), lr=learningRate, momentum=momentum)\n",
        "\n",
        "print('>>> Beginning training!')\n",
        "\n",
        "cnn.train()\n",
        "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
        "    cnnRunningLoss = 0\n",
        "    for i, (inputs, labels) in enumerate(trainLoader, 0):\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "\n",
        "        cnnOutputs = cnn(inputs)\n",
        "\n",
        "        # Backpropagation\n",
        "\n",
        "        cnnLoss = criterion(cnnOutputs, labels)\n",
        "\n",
        "        cnnLoss.backward()\n",
        "\n",
        "        # Gradient update\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        cnnRunningLoss += cnnLoss.item()\n",
        "        if (i+1) % 2000 == 0:    # print every 2000 mini-batches\n",
        "            print('Epoch [{}/{}], Step [{}/{}],  CNN Loss: {}'.format(epoch + 1, numEpochs, i + 1, len(trainDataset)//4,  cnnRunningLoss/2000))\n",
        "            cnnRunningLoss = 0\n",
        "\n",
        "print()\n",
        "print('>>> Beginning validation!')\n",
        "\n",
        "cnn.eval()\n",
        "cnnCorrect =  0\n",
        "total = 0\n",
        "for inputs, labels in testLoader:\n",
        "\n",
        "\n",
        "    cnnOutputs = cnn(inputs)\n",
        "\n",
        "    _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "\n",
        "    cnnCorrect += (cnnPredicted == labels).sum().item()\n",
        "print('CNN validation accuracy: {}%'.format(cnnCorrect / total * 100))"
      ],
      "metadata": {
        "id": "CqmmSwdlpTc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMJgv7gcpTfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s8-OnHMFpTh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_iwtWW3pTkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}