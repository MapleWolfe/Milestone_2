{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MapleWolfe/Milestone_2/blob/Jai/Unsupervised%20learning%20notebook\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised and Supervised Learning techniques"
      ],
      "metadata": {
        "id": "IuuckSotcRHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installs, imports, pre-sets"
      ],
      "metadata": {
        "id": "Uv1syv3gdvb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py\n",
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "id": "qudk0RcgDLyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d477350f-f741-451c-e6b4-7660b6f8ca5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 390, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 390 (delta 89), reused 51 (delta 51), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (390/390), 107.11 KiB | 5.95 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 2.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n",
            "***********************************************************************\n",
            "Woo! Your instance has the right kind of GPU, a Tesla T4!\n",
            "We will now install RAPIDS cuDF, cuML, and cuGraph via pip! \n",
            "Please stand by, should be quick...\n",
            "***********************************************************************\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.nvidia.com\n",
            "Collecting cudf-cu11\n",
            "  Downloading https://pypi.nvidia.com/cudf-cu11/cudf_cu11-23.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 489.3/489.3 MB 3.1 MB/s eta 0:00:00\n",
            "Collecting cuml-cu11\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu11/cuml_cu11-23.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1079.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 GB 1.7 MB/s eta 0:00:00\n",
            "Collecting cugraph-cu11\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu11/cugraph_cu11-23.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1160.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 1.7 MB/s eta 0:00:00\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 14.5 MB/s eta 0:00:00\n",
            "Collecting cubinlinker-cu11\n",
            "  Downloading https://pypi.nvidia.com/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 105.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (23.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (2023.4.0)\n",
            "Collecting protobuf<4.22,>=4.21.6\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 41.7 MB/s eta 0:00:00\n",
            "Collecting pyarrow==11.*\n",
            "  Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.9/34.9 MB 11.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (4.5.0)\n",
            "Collecting numba>=0.57\n",
            "  Downloading numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 82.8 MB/s eta 0:00:00\n",
            "Collecting cupy-cuda11x>=12.0.0\n",
            "  Downloading cupy_cuda11x-12.1.0-cp310-cp310-manylinux2014_x86_64.whl (89.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.3/89.3 MB 18.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (1.22.4)\n",
            "Collecting nvtx>=0.2.1\n",
            "  Downloading nvtx-0.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 428.4/428.4 kB 44.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (5.3.0)\n",
            "Requirement already satisfied: pandas<1.6.0dev0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (1.5.3)\n",
            "Collecting cuda-python<12.0,>=11.7.1\n",
            "  Downloading cuda_python-11.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 88.0 MB/s eta 0:00:00\n",
            "Collecting ptxcompiler-cu11\n",
            "  Downloading https://pypi.nvidia.com/ptxcompiler-cu11/ptxcompiler_cu11-0.7.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 111.5 MB/s eta 0:00:00\n",
            "Collecting rmm-cu11==23.6.*\n",
            "  Downloading https://pypi.nvidia.com/rmm-cu11/rmm_cu11-23.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 84.2 MB/s eta 0:00:00\n",
            "Collecting treelite-runtime==3.2.0\n",
            "  Downloading treelite_runtime-3.2.0-py3-none-manylinux2014_x86_64.whl (198 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 198.2/198.2 kB 25.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.10.1)\n",
            "Collecting dask==2023.3.2\n",
            "  Downloading dask-2023.3.2-py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 40.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.2.0)\n",
            "Collecting dask-cuda==23.6.*\n",
            "  Downloading dask_cuda-23.6.0-py3-none-any.whl (125 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.2/125.2 kB 15.5 MB/s eta 0:00:00\n",
            "Collecting dask-cudf-cu11==23.6.*\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu11/dask_cudf_cu11-23.6.0-py3-none-any.whl (79 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 12.1 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu11==23.6.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu11/raft_dask_cu11-23.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 214.3/214.3 MB 3.9 MB/s eta 0:00:00\n",
            "Collecting treelite==3.2.0\n",
            "  Downloading treelite-3.2.0-py3-none-manylinux2014_x86_64.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 66.5 MB/s eta 0:00:00\n",
            "Collecting distributed==2023.3.2.1\n",
            "  Downloading distributed-2023.3.2.1-py3-none-any.whl (957 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 957.1/957.1 kB 61.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (6.0)\n",
            "Collecting importlib-metadata>=4.13.0\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (1.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (8.1.3)\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==23.6.*->cuml-cu11) (3.0.0)\n",
            "Collecting pynvml<11.5,>=11.0.0\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 6.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.4.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.0)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.26.15)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (6.2)\n",
            "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (5.9.5)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.5)\n",
            "Collecting pylibraft-cu11==23.6.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu11/pylibraft_cu11-23.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 471.7/471.7 MB 3.1 MB/s eta 0:00:00\n",
            "Collecting ucx-py-cu11==0.32.*\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu11/ucx_py_cu11-0.32.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 115.5 MB/s eta 0:00:00\n",
            "Collecting pylibcugraph-cu11==23.6.*\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu11/pylibcugraph_cu11-23.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1159.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 1.7 MB/s eta 0:00:00\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 31.3 MB/s eta 0:00:00\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 17.0 MB/s eta 0:00:00\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 21.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<12.0,>=11.7.1->cudf-cu11) (0.29.34)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x>=12.0.0->cudf-cu11) (0.8.1)\n",
            "Collecting llvmlite<0.41,>=0.40.0dev0\n",
            "  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 40.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11) (2.8.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2023.3.2->cuml-cu11) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2023.3.2.1->cuml-cu11) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.3->cudf-cu11) (1.16.0)\n",
            "Installing collected packages: ptxcompiler-cu11, nvtx, cubinlinker-cu11, pynvml, pyarrow, protobuf, multidict, llvmlite, importlib-metadata, frozenlist, cupy-cuda11x, cuda-python, async-timeout, yarl, ucx-py-cu11, treelite-runtime, treelite, numba, dask, aiosignal, rmm-cu11, distributed, aiohttp, pylibraft-cu11, dask-cuda, cudf-cu11, raft-dask-cu11, pylibcugraph-cu11, dask-cudf-cu11, cuml-cu11, cugraph-cu11\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.0\n",
            "    Uninstalling pynvml-11.5.0:\n",
            "      Successfully uninstalled pynvml-11.5.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: cupy-cuda11x\n",
            "    Found existing installation: cupy-cuda11x 11.0.0\n",
            "    Uninstalling cupy-cuda11x-11.0.0:\n",
            "      Successfully uninstalled cupy-cuda11x-11.0.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.12.1\n",
            "    Uninstalling dask-2022.12.1:\n",
            "      Successfully uninstalled dask-2022.12.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.12.1\n",
            "    Uninstalling distributed-2022.12.1:\n",
            "      Successfully uninstalled distributed-2022.12.1\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cubinlinker-cu11-0.3.0.post1 cuda-python-11.8.2 cudf-cu11-23.6.0 cugraph-cu11-23.6.2 cuml-cu11-23.6.0 cupy-cuda11x-12.1.0 dask-2023.3.2 dask-cuda-23.6.0 dask-cudf-cu11-23.6.0 distributed-2023.3.2.1 frozenlist-1.3.3 importlib-metadata-6.7.0 llvmlite-0.40.1 multidict-6.0.4 numba-0.57.1 nvtx-0.2.5 protobuf-4.21.12 ptxcompiler-cu11-0.7.0.post1 pyarrow-11.0.0 pylibcugraph-cu11-23.6.2 pylibraft-cu11-23.6.1 pynvml-11.4.1 raft-dask-cu11-23.6.1 rmm-cu11-23.6.0 treelite-3.2.0 treelite-runtime-3.2.0 ucx-py-cu11-0.32.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cupy-cuda11x in /usr/local/lib/python3.10/dist-packages (12.1.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (0.8.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (1.22.4)\n",
            "\n",
            "          ***********************************************************************\n",
            "          The pip install of RAPIDS is complete.\n",
            "          \n",
            "          Please do not run any further installation from the conda based installation methods, as they may cause issues!  \n",
            "          \n",
            "          Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts. \n",
            "r          \n",
            "          Troubleshooting:\n",
            "             - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "             - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "          ***********************************************************************\n",
            "          \n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.11.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.3.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.21.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.59.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_fG6RA56XD_4"
      },
      "outputs": [],
      "source": [
        "#google import options\n",
        "#from google.colab import drive\n",
        "from google.cloud import storage\n",
        "\n",
        "#general usage imports\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import gc\n",
        "import os\n",
        "import multiprocessing\n",
        "import torch\n",
        "import pickle\n",
        "import json\n",
        "#clustering import\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# GPU Imports below\n",
        "#import cudf\n",
        "#import cupy as cp\n",
        "#import cuml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cpus = multiprocessing.cpu_count()\n",
        "print(\"Number of available CPUs:\", num_cpus)\n",
        "\n",
        "# Get the number of available GPUs\n",
        "num_gpus = torch.cuda.device_count()\n",
        "print(\"Number of available GPUs:\", num_gpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raB23_8jCqUs",
        "outputId": "36abecd0-5f71-4b48-ddc0-e0fca4c7919b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available CPUs: 16\n",
            "Number of available GPUs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCP set up"
      ],
      "metadata": {
        "id": "TnpY5qVHuE9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/organic-reef-390716-609989a4c6da.json'\n",
        "client = storage.Client()\n",
        "bucket = client.get_bucket('fire_train_eval_test_bucket')\n",
        "blob = bucket.blob('test.csv')\n",
        "blob.download_to_filename('test.csv')\n",
        "blob = bucket.blob('eval.csv')\n",
        "blob.download_to_filename('eval.csv')\n",
        "blob = bucket.blob('train.csv')\n",
        "blob.download_to_filename('train.csv')"
      ],
      "metadata": {
        "id": "Wi1hP1Hbs7sB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to load csv chunks"
      ],
      "metadata": {
        "id": "B_yF4lBdd2_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's mount the drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rG2_aSl8ArTm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remember to add .csv at the end of file name\n",
        "def read_csv_in_chunks(file_name,number_images):\n",
        "\n",
        "  #number of rows per image:\n",
        "  pixels_count = 64*64\n",
        "\n",
        "  #upto 200 images at a time\n",
        "  size = number_images*pixels_count\n",
        "\n",
        "  #file string and location for Google Drive\n",
        "  #file_string = '/content/drive/MyDrive/' + file_name\n",
        "\n",
        "  #file string and location for Google cloud storage\n",
        "  file_string = '/content/' + file_name\n",
        "  return pd.read_csv(file_string, chunksize=size)\n",
        "\n",
        "def read_full_csv(file_name):\n",
        "  #file string and location for Google Drive\n",
        "  #file_string = '/content/drive/MyDrive/' + file_name\n",
        "\n",
        "  #file string and location for Google cloud storage\n",
        "  file_string = '/content/' + file_name\n",
        "\n",
        "\n",
        "  return pd.read_csv(file_string)"
      ],
      "metadata": {
        "id": "wwtDvsYWPRUi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to clean CSV chunks"
      ],
      "metadata": {
        "id": "TmldQYHo52YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is procedure that cleans the data.\n",
        "# cleaner_1 drops all negative \"firemask\" values and converts all values above 0 to 1\n",
        "def cleaner_1(df_chunk):\n",
        "  col_list = ['NDVI_scaled_smoothened_values', 'NDVI_local_gradient', 'NDVI_local_mean', 'tmmn_scaled_smoothened_values', 'tmmn_local_gradient', 'tmmn_local_mean', 'elevation_scaled_smoothened_values', 'elevation_local_gradient', 'elevation_local_mean', 'fire_at_similar_altitude', 'population_scaled_smoothened_values', 'population_local_gradient', 'population_local_mean', 'vs_scaled_smoothened_values', 'vs_local_gradient', 'vs_local_mean', 'pdsi_scaled_smoothened_values', 'pdsi_local_gradient', 'pdsi_local_mean', 'pr_scaled_smoothened_values', 'pr_local_gradient', 'pr_local_mean', 'tmmx_scaled_smoothened_values', 'tmmx_local_gradient', 'tmmx_local_mean', 'sph_scaled_smoothened_values', 'sph_local_gradient', 'sph_local_mean', 'th_scaled_smoothened_values', 'th_local_gradient', 'th_local_mean', 'distance_from_fire', 'erc_scaled_smoothened_values', 'erc_local_gradient', 'erc_local_mean']\n",
        "  df_chunk['PrevFireMask'] = df_chunk['PrevFireMask'].astype(float)\n",
        "  df_chunk['FireMask'] = df_chunk['FireMask'].astype(float)\n",
        "\n",
        "  original_previous_day_fire = df_chunk['PrevFireMask']\n",
        "  original_next_day_fire = df_chunk['FireMask']\n",
        "\n",
        "  #general cleaning for classifier and regressor\n",
        "  drop_neg_df = df_chunk[df_chunk['FireMask'] >=0]\n",
        "\n",
        "  #only regressor selection\n",
        "  regressor_target = drop_neg_df['FireMask']\n",
        "\n",
        "  #cleaning specifically for the classifier\n",
        "  classifier_target = np.where(regressor_target > 0, 1, 0)\n",
        "  dropped_chunk = df_chunk.drop(labels=['PrevFireMask','FireMask','image_id'], axis=1)\n",
        "  output_chunk = dropped_chunk[col_list]\n",
        "  return output_chunk,regressor_target,classifier_target, original_previous_day_fire, original_next_day_fire"
      ],
      "metadata": {
        "id": "JoAEDwdU51eF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised Learning"
      ],
      "metadata": {
        "id": "nmWk-aGU6XXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cluster evaluation functions"
      ],
      "metadata": {
        "id": "IGLZLiHp5l4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_evaluation(eval_df, cluster_model):\n",
        "    print('evaluation start')\n",
        "    eval_labels = cluster_model.predict(eval_df)\n",
        "    inertia = cluster_model.inertia_\n",
        "    calinski = calinski_harabasz_score(eval_df, eval_labels)\n",
        "    davies_bouldin = davies_bouldin_score(eval_df, eval_labels)\n",
        "    # we are no longer calculating silhouette score as it performs pairwise calculations that grow exponentially\n",
        "    #silhouette = silhouette_score(eval_df, eval_labels)\n",
        "\n",
        "    print('evaluation complete')\n",
        "    return inertia, calinski, davies_bouldin"
      ],
      "metadata": {
        "id": "fqXUlzjO5j7E"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kmeans Clustering"
      ],
      "metadata": {
        "id": "Xt1apEuP6qRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets build a function for our kmeans cluster\n",
        "def search_params_kmeans(file_name='train.csv',number_images=1000,cluster_list=[8,32,64],initialisation_list = ['k-means++', 'random']):\n",
        "  k_means_param_grid = {'n_clusters': cluster_list, 'init': initialisation_list, 'batch_size' : [4096]}\n",
        "\n",
        "  for params in ParameterGrid(k_means_param_grid):\n",
        "    print('initializing kmeans for param: ', params)\n",
        "    csv_chunks_generator = read_csv_in_chunks(file_name,number_images)\n",
        "    K_means_model = MiniBatchKMeans(**params)\n",
        "    counter = 0\n",
        "    for a_chunk in csv_chunks_generator:\n",
        "      features_df,_,_,_,_ = cleaner_1(a_chunk)\n",
        "      K_means_model.partial_fit(features_df)\n",
        "      print('iteration completed: ', counter)\n",
        "      counter+=1\n",
        "    yield K_means_model, params"
      ],
      "metadata": {
        "id": "5ii7V710rRCf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# a dict to store model performance & eval csv file\n",
        "print('starting to read evaluation dataset')\n",
        "evaluation_df = read_full_csv('eval.csv')\n",
        "print('read eval')\n",
        "cleaned_eval,_,_,_,_ = cleaner_1(evaluation_df)\n",
        "\n",
        "#intermediate memory step\n",
        "print('starting deletion of raw evaluation data')\n",
        "del evaluation_df\n",
        "gc.collect()\n",
        "print('completed deletion of raw evaluation data')\n",
        "\n",
        "# initiating model building\n",
        "model_builders = search_params_kmeans(file_name='train.csv')\n",
        "model_perform_dict ={}\n",
        "model_counter = 0\n",
        "#this where a lot of time will go, it will iterate over each model across grid search\n",
        "for a_kmean_model, kmean_params in model_builders:\n",
        "  model_counter +=1\n",
        "  print('initializing evaluation')\n",
        "  inertia, calinski, davies_bouldin = cluster_evaluation(cleaned_eval, a_kmean_model)\n",
        "  print('evaluation complete')\n",
        "\n",
        "  model_name = 'kmean_model_'+str(model_counter)\n",
        "  model_perform_dict[model_name]=[kmean_params,inertia, calinski, davies_bouldin]\n",
        "  print('storing model')\n",
        "  with open(model_name, 'wb') as model_file:\n",
        "    pickle.dump(a_kmean_model, model_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT0KhYBp91ng",
        "outputId": "2334f2d2-454c-496f-d762-cf26f119b245"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to read evaluation dataset\n",
            "read eval\n",
            "starting deletion of raw evaluation data\n",
            "completed deletion of raw evaluation data\n",
            "initializing kmeans for param:  {'batch_size': 4096, 'init': 'k-means++', 'n_clusters': 8}\n",
            "iteration completed:  0\n",
            "iteration completed:  1\n",
            "iteration completed:  2\n",
            "iteration completed:  3\n",
            "iteration completed:  4\n",
            "iteration completed:  5\n",
            "iteration completed:  6\n",
            "iteration completed:  7\n",
            "iteration completed:  8\n",
            "iteration completed:  9\n",
            "iteration completed:  10\n",
            "iteration completed:  11\n",
            "iteration completed:  12\n",
            "iteration completed:  13\n",
            "iteration completed:  14\n",
            "initializing evaluation\n",
            "evaluation start\n",
            "evaluation complete\n",
            "evaluation complete\n",
            "storing model\n",
            "initializing kmeans for param:  {'batch_size': 4096, 'init': 'k-means++', 'n_clusters': 32}\n",
            "iteration completed:  0\n",
            "iteration completed:  1\n",
            "iteration completed:  2\n",
            "iteration completed:  3\n",
            "iteration completed:  4\n",
            "iteration completed:  5\n",
            "iteration completed:  6\n",
            "iteration completed:  7\n",
            "iteration completed:  8\n",
            "iteration completed:  9\n",
            "iteration completed:  10\n",
            "iteration completed:  11\n",
            "iteration completed:  12\n",
            "iteration completed:  13\n",
            "iteration completed:  14\n",
            "initializing evaluation\n",
            "evaluation start\n",
            "evaluation complete\n",
            "evaluation complete\n",
            "storing model\n",
            "initializing kmeans for param:  {'batch_size': 4096, 'init': 'k-means++', 'n_clusters': 64}\n",
            "iteration completed:  0\n",
            "iteration completed:  1\n",
            "iteration completed:  2\n",
            "iteration completed:  3\n",
            "iteration completed:  4\n",
            "iteration completed:  5\n",
            "iteration completed:  6\n",
            "iteration completed:  7\n",
            "iteration completed:  8\n",
            "iteration completed:  9\n",
            "iteration completed:  10\n",
            "iteration completed:  11\n",
            "iteration completed:  12\n",
            "iteration completed:  13\n",
            "iteration completed:  14\n",
            "initializing evaluation\n",
            "evaluation start\n",
            "evaluation complete\n",
            "evaluation complete\n",
            "storing model\n",
            "initializing kmeans for param:  {'batch_size': 4096, 'init': 'random', 'n_clusters': 8}\n",
            "iteration completed:  0\n",
            "iteration completed:  1\n",
            "iteration completed:  2\n",
            "iteration completed:  3\n",
            "iteration completed:  4\n",
            "iteration completed:  5\n",
            "iteration completed:  6\n",
            "iteration completed:  7\n",
            "iteration completed:  8\n",
            "iteration completed:  9\n",
            "iteration completed:  10\n",
            "iteration completed:  11\n",
            "iteration completed:  12\n",
            "iteration completed:  13\n",
            "iteration completed:  14\n",
            "initializing evaluation\n",
            "evaluation start\n",
            "evaluation complete\n",
            "evaluation complete\n",
            "storing model\n",
            "initializing kmeans for param:  {'batch_size': 4096, 'init': 'random', 'n_clusters': 32}\n",
            "iteration completed:  0\n",
            "iteration completed:  1\n",
            "iteration completed:  2\n",
            "iteration completed:  3\n",
            "iteration completed:  4\n",
            "iteration completed:  5\n",
            "iteration completed:  6\n",
            "iteration completed:  7\n",
            "iteration completed:  8\n",
            "iteration completed:  9\n",
            "iteration completed:  10\n",
            "iteration completed:  11\n",
            "iteration completed:  12\n",
            "iteration completed:  13\n",
            "iteration completed:  14\n",
            "initializing evaluation\n",
            "evaluation start\n",
            "evaluation complete\n",
            "evaluation complete\n",
            "storing model\n",
            "initializing kmeans for param:  {'batch_size': 4096, 'init': 'random', 'n_clusters': 64}\n",
            "iteration completed:  0\n",
            "iteration completed:  1\n",
            "iteration completed:  2\n",
            "iteration completed:  3\n",
            "iteration completed:  4\n",
            "iteration completed:  5\n",
            "iteration completed:  6\n",
            "iteration completed:  7\n",
            "iteration completed:  8\n",
            "iteration completed:  9\n",
            "iteration completed:  10\n",
            "iteration completed:  11\n",
            "iteration completed:  12\n",
            "iteration completed:  13\n",
            "iteration completed:  14\n",
            "initializing evaluation\n",
            "evaluation start\n",
            "evaluation complete\n",
            "evaluation complete\n",
            "storing model\n",
            "CPU times: user 29min 2s, sys: 9min 29s, total: 38min 32s\n",
            "Wall time: 30min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a_key in model_perform_dict.keys():\n",
        "  #inertia, calinski, davies_bouldin\n",
        "  model_perform_dict[a_key][1] = ('inertia',model_perform_dict[a_key][1])\n",
        "  model_perform_dict[a_key][2] = ('calinski',model_perform_dict[a_key][2])\n",
        "  model_perform_dict[a_key][3] = ('davies_bouldin',model_perform_dict[a_key][3])\n",
        "\n",
        "#outputing our evaluation metrics for all the models\n",
        "with open('kmean_model_performance.json', 'w') as kmeans_metric_json:\n",
        "    json.dump(model_perform_dict, kmeans_metric_json)"
      ],
      "metadata": {
        "id": "hcBuqpiAyvVa"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_perform_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YeLeY8Xy_ea",
        "outputId": "29de927f-3c86-4a0c-9bc1-e08b74318b01"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'kmean_model_1': [{'batch_size': 4096, 'init': 'k-means++', 'n_clusters': 8}, ('inertia', 103444457141.6807), ('calinski', 947824.1873928448), ('davies_bouldin', 1.5350989882310406)], 'kmean_model_2': [{'batch_size': 4096, 'init': 'k-means++', 'n_clusters': 32}, ('inertia', 73451307334.58064), ('calinski', 498265.75712045544), ('davies_bouldin', 1.8656431872536667)], 'kmean_model_3': [{'batch_size': 4096, 'init': 'k-means++', 'n_clusters': 64}, ('inertia', 65233599304.176216), ('calinski', 393700.77784573444), ('davies_bouldin', 1.9156620251887275)], 'kmean_model_4': [{'batch_size': 4096, 'init': 'random', 'n_clusters': 8}, ('inertia', 99524305063.17825), ('calinski', 777417.5990288019), ('davies_bouldin', 1.6285391359846724)], 'kmean_model_5': [{'batch_size': 4096, 'init': 'random', 'n_clusters': 32}, ('inertia', 78771376268.703), ('calinski', 505692.9775275081), ('davies_bouldin', 1.8112786440385424)], 'kmean_model_6': [{'batch_size': 4096, 'init': 'random', 'n_clusters': 64}, ('inertia', 60684932556.10132), ('calinski', 408396.452725546), ('davies_bouldin', 1.9577769149217332)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "820XsmUwGC5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hdbscan clustering"
      ],
      "metadata": {
        "id": "gGOydEOH6tce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PCA"
      ],
      "metadata": {
        "id": "VfpJGDAq68xJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Auto Encoder"
      ],
      "metadata": {
        "id": "ul4FPGl57I4P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BoWizoj9JYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised learning (Classifier)"
      ],
      "metadata": {
        "id": "u6hYhaR69PoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### logistic classifier"
      ],
      "metadata": {
        "id": "VLjtD66Q9dDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Bayes classifier"
      ],
      "metadata": {
        "id": "U8OcJM3r_s0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGB Classifier"
      ],
      "metadata": {
        "id": "oTJOYxCO9glu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for a_chunk in read_csv_in_chunks('train.csv',1000):"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y10IMkS9SVSz",
        "outputId": "ad792064-532e-4dde-83ed-2b986e1a23d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  :  454\n",
            "1  :  1456\n",
            "2  :  2003\n",
            "3  :  2504\n",
            "4  :  3507\n",
            "5  :  4510\n",
            "6  :  4824\n",
            "7  :  5265\n",
            "8  :  5676\n",
            "9  :  5905\n",
            "10  :  6323\n",
            "11  :  7326\n",
            "12  :  7782\n",
            "13  :  8785\n",
            "14  :  9262\n"
          ]
        }
      ]
    }
  ]
}